import numpy as np
import os
import pandas as pd
import re
import shutil

def exist_or_make(path: str) -> None:
    """
    Function that checks for existance of required directories and creates them if they don't exist
    
    @param path: path to a directory required by script
    @returns: creates directories, returns nothing 
    """
    if not os.path.isdir(path):
        os.makedirs(path)
        
def check_new(database: list, url_dict: dict) -> list:
    """
    Function that filters list of all URLs to only new URLs
    
    @param database: a list of all CL post ids currently in text database
    @param url_dict: a dict of URLs to be checked against URLs already scraped, generated by extract_links()
    @returns: filtered list of only new URLs
    """
    # for ids not in database, return url
    new=[url_dict[key] for key, value in url_dict.items() if int(key) not in database]
    return(new)

def create_paths(base_path: str) -> list:
    """
    Function that takes in a base path and outputs directories for data and log files
    
    @param base_path: base output path for files
    @returns a list with: log_path and database_path
    """
    log_path=os.path.join(base_path, 'logs')
    database_path=os.path.join(base_path, 'database')
    out=[log_path, database_path]
    [exist_or_make(x) for x in out]
    return(out)

def get_first(values: list):
    """
    Function that takes in a list and returns the first value (and the .text attribute if it exists), otherwise returns nothing
    
    @param values: list that contains 0-many results
    @returns: the first item of the list or None
    """
    out=None
    if len(values) > 0:
        out=values[0]
        if out.text:
            out=out.text.strip()
    return(out)

def generate_search_urls(stem: str, max_res: int) -> list:
    """
    Function that generates a list of craigslist URLs for each page of the search defined in stem 
    
    @param stem: a base craiglist URL describing a rental search
    @param max_res: the total number of search results (determined by search_links())
    @returns: a list of URLs for each page of a craiglist search
    """
    ## generate urls to grab all results
    search_limit=120
    url_list=[]
    if max_res > search_limit:
        for i in range(1, int(np.floor(max_res/120))+1):
            num=search_limit * i
            link=stem + '&s=' + str(num)
            url_list.append(link)
    return(url_list)

def filter_spam(df):
    """
    Function that takes in the craigslist database pd.DataFrame and subsets to likely real postings
    
    @param df: pd.DataFrame output by make_output()
    @returns: pd.DataFrame with spam listings removed
    """
    spam_bool=((df.num_images > 2) & (df.scam == False) & \
               (df.emoji < 2) & (df.links == False) & \
               (pd.notnull(df.latitude)))
    clean=df[spam_bool]
    return(clean)
